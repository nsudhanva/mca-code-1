#determining the target is known as Extrapolation - given y we need to find x, this is known as extrapolation
# Logistic growth model will be best explainable when the data has reached the upper limit and there after the growth is consistent, logistic growth model can be used
logisticFit(sample$x, sample$y)
tripleFit(sample$x, sample$y)
# R-squared = 1 - (Explained variation) / Total variation
expFitPred(sample$x, sample$y, 1)
tripleFit(sample$x, sample$y)
fix(sample)
fix(sample)
linFit(sample$x, sample$y)
linFitPred(sample$x, sample$y, 1)
linFit(sample$x, sample$y)
linFitPred(sample$x, sample$y, 1)
linFitPred(sample$x, sample$y, 2)
mean(sample$x)
mean(sample$y)
fix(sample)
library(readr)
sample <- read_csv("D:/Study/3rd Sem/IDS/sample.csv")
View(sample)
linFit(sample$x, sample$y)
linFitPred(sample$x, sample$y, 1)
linFitPred(sample$x, sample$y, 2)
mean(sample$x)
mean(sample$y)
# Exponential model
expFit(sample$x, sample$y)
# R-squared = 1 - (Explained variation) / Total variation
expFitPred(sample$x, sample$y, 1)
#determining the target is known as Extrapolation - given y we need to find x, this is known as extrapolation
# Logistic growth model will be best explainable when the data has reached the upper limit and there after the growth is consistent, logistic growth model can be used
logisticFit(sample$x, sample$y)
tripleFit(sample$x, sample$y)
#determining the target is known as Extrapolation - given y we need to find x, this is known as extrapolation
# Logistic growth model will be best explainable when the data has reached the upper limit and there after the growth is consistent, logistic growth model can be used
logisticFit(sample$x, sample$y)
logisticFit(sample$x, sample$y, 1)
logisticFit(sample$x, sample$y, 2)
1-.95
116-100/16/sqrt(16)
sqrt
sqrt(16)
116-100/(16/sqrt(16))
(16/sqrt(16))
116-100/4
(116-100)/4
(116-100)/(16/sqrt(16))
2(0.8849)
2*(0.8849)
(116-100)/(10/4)
(29-31)/(2.7/sqrt(8))
40/20 * sqrt(30)
(140-100)/(20/sqrt(30))
(1260/5230) * sqrt(30)
(43260-42000)/(5230/sqrt(30))
mu = 10000
xbar = 9900
sigma = 120
n = 30
alpha = 0.05
cv = qnorm(1-alpha) #qnorm gives x value
cv
z = (xbar-mu)/(sigma/sqrt(n))
z
cv = -cv
#compute p value
p = pnorm
library(BSDA)
x = rnorm(mean = 9900, sd = 110, n = 30)
#Data consisting of two variables - bivariate data
#more than two variables - multivariate data
# most real time data is multivariate
# correlation coefficient - The statistical tool that measures the strength and direction of the linear relationship between two numerical variables
height = c(180,176,144,195,159,185,166,173,149,168)
weight = c(87,55,52,94,95,59,85,66,73,49)
plot(type = "p", height, weight)
library(corrplot)
head(BikeData, 10)
bikeData
library(readr)
BikeData <- read_csv("D:/Study/3rd Sem/IDS/BikeData.csv")
View(BikeData)
head(BikeData, 10)
plot(BikeData$distance)
plot(BikeData$distance, col = "red")
plot(BikeData$distance, col = "red", xlab = "distance", ylab = "speed")
plot(BikeData$distance, col = "red", xlab = "distance", ylab = "speed", main = "Bike Distance")
boxplot(BikeData$distance, data = bike, xlab = "Distance", main = "Sales Data")
boxplot(BikeData$distance, data = BikeData, xlab = "Distance", main = "Sales Data")
x = 2.987
while(x <= 4.987)
{
x = x + 0.987
print(c(x,x-2,x-1))
}
a = -3
repeat
{
print(a)
a = a+1
if(a > 5)
break
}
a = -3
repeat
{
print(a)
a = a+1
if(a > 5)
continue
}
a = -3
repeat
{
print(a)
a = a+1
if(a > 5)
break
}
x = 1:4
for(i in x)
{
if(i == 2)
{
next
}
print(i)
}
x = 1:10
for(i in x)
{
if(i == 2)
{
break
}
print(i)
}
x = "Vijaykumar"
substr(x,1,2)
substr(x,1,5)
grep(vijay,x)
grep("vijay",x)
grep("v",x)
grep("jay",x)
grep("new",x)
toupper(x)
tolower(x)
strsplit(x, split)
strsplit(x)
strsplit(x, "")
words = c("R", "Data Science", "Machine Learning", "Algorithms", "AI")
words.names = function(x)
{
for(name in x)
{
print(name)
}
}
words.names(words)
words = c("R", "Data Science", "Machine Learning", "Algorithms", "AI")
words.names = function(x)
{
for(name in x)
{
print(name)
}
}
words.names(words)
my_oranges = 6
my_apples = 5
my_fruits = my_oranges + my_apples
print(my_fruits)
class(my_fruits)
is.character(my_fruits)
is.numeric(my_fruits)
as.numeric(my_fruits)
as.character(my_fruits)
my_n = 42.4
my_c = "Universal"
my_l = FALSE
print(my_n)
print(my_c)
print(my_l)
class(my_c)
class(my_n)
class(my_l)
as.integer(42.4)
as.integer(my_n)
my_c = universe
my_c = my_c + "truth"
print(my_c)
paste(my_c, "truth")
my_fruits = c(apple = 1, guava = 1, strawberry = 10)
my_fruits
6%/%2
6%%2
6%2
6/2
6/5
6%/%2
6%/%5
true|FALSE
TRUE|FALSE
TRUE||FALSE
FALSE|TRUE
TRUE&FALSE
TRUE&&FALSE
X = c(1:10)
X
(X>=10)|(X<10)
(X>=10)||(X<10)
as.factor(c("North", "South", "East", "West"))
str(my_apples)
a = c(a[1:2],11,12,a[3:6])
a
[print(a[1])]
print(a[1])
print(a[1:2])
prin(a[1:2],[-7,-8])
print(a[1:2],[-7:-8])
print(a[-7:-8])
print(c(a[1:2],a[8:9]))
a
a = sort(a,decreasing = TRUE)
d = sort(a)
a = sort(a,decreasing = TRUE)
a = seq(1,100,by = 2)
a = sort(a,decreasing = TRUE)
a
a = 1:100
a
a = seq(1,100,by = 2)
a
a = c("red", "white", "yellow")
a
class(a)
a = 1:10
b = 11:20
c = a + b
a* b
b = 1:5
a * b
a[2] * 4
a = 10
b = 2
a / b
b = 3
a / b
b = 2
a % b
a %% b
a // b
a %/% b
c = 3
a %/% b
a %/% c
a / c
a = matrix(1:10, nrow = 5)
a
a = matrix(1:10, ncol = 5)
a
z = LETTERS[1:26]
z
a = sort(rep('a',2)(1,1))
LETTERS[1:26]
a = 1:10000
a = c(1,2,NA,4)
a
a = na.omit(a)
a
a = 1:10000
b = sample(a,100)
b
b = sample(a,100, replace = TRUE) #When population is small, use replace so that you get different values
b
x = "Vijayakumar"
substr(x, start = 1, stop = 5)
grep("a",x,ignore.case = FALSE, fixed = FALSE)
sub("akumar","pai",x,ignore.case = FALSE, fixed = FALSE)
strsplit(x, "")
y = "kumar"
paste("Vijay",y)
toupper(x)
tolower(x)
a = 1:10
mean(a)
mean(3424233.124241, trim = 0.1)
mean(a, na.rm = TRUE)
length(a)
a = na.omit(a)
na.rm(a)
sd(a)
median(a)
quantile(a) #very important
names = c("Vijay","Ayush","Sudhanva")
age = c(23,22,23)
salary = c(100000,200000,300000)
employees = data.frame(names = c("Vijay","Ayush","Sudhanva"), age = c(23, 22, 23), salary = c("100000","200000","300000"))
employees
words = c("R", "Data Science", "Machine Learning", "Algorithms", "AI")
words.names = function(x)
{
for(name in x)
{
print(name)
}
}
words.names(words)
findHighSalary = function(df)
{
Maxsal = 0
names = ""
for(i in 1:nrow((employees)))
{
tmpsal = as.numeric(employees[1,3])
if(tmpsal > Maxsal)
{
Maxsal = tmpsal
names = employees[i,1]
}
}
return(as.character((names)))
}
findHighSalary(employees)
student = data.frame(srn = c(1,5,7),name = c("Radha", "Krishna", "Rama"))
student
student$srn
student$name
student$srn == 5
emp.data <- data.frame(emp_id = c(1:5), emp_name = c("Ricky", "Danish", "Mini", "Ryan", "Gary"), salary = c(600,500,671,729,943))
emp.data
dim(student)
nrow(student)
fix(student)
setwd("~/")
setwd("D:/Study/3rd Sem/IDS/Programs")
c = data.frame(a,b)
str(c)
k = student[student$srn == 5, student$name == "Krishna"]
k
barplot(BikeData$distance)
barplot(BikeData$distance, col = c("black", "red"), xlab = "distance", ylab = "distance measure", main = "distance travelled")
hist(BikeData$speed, col = c("red", "yellow", "green", "violet"), xlab = "speed", ylab = "speed measured", main = "speed of riders")
barplot(table(BikeData$student))
y = table(BikeData$student)
barplot(y)
pie(y)
barplot(y, names.arg = c("Not Student", "Student"))
pie(table(BikeData$cyc_freq), col = c("red", "yellow", "green", "violet"))
pie(table(BikeData$cyc_freq), col = c("red", "yellow", "green", "violet"), clockwise = TRUE)
pie(table(BikeData$cyc_freq), col = c("red", "yellow", "green", "violet"), clockwise = TRUE)
table(BikeData$cyc_freq)
y = aggregate(distance~cyc_freq, BikeData, mean)
y
barplot(table(y), col = c("red", "yellow", "green", "blue"))
x = c(rep(1,3),4,5,rep(6,7))
v = c(9,13,21,8,36,22,12,41,31,33,19)
x
hist(x)
hist(x, breaks = 3)
hist(x, breaks = 3, xlim = c(0,40))
#plot(v, type, col, xlab, ylab)
plot(x, type = "o", col = c("black", "red"), xlab = "frequency", ylab = "type")
v = c(7,12,28,3,41)
t = c(14,7,6,19,3)
y = c(1,4,5,4,6,6,6,6)
lines(y, type = "o")
plot(x, type = "o")
colors = c("green", "orange", "brown")
months = c("Mar", "Apr", "May", "Jun", "Jul")
regions = c("East","West","North")
values = matrix(c(2,9,3,11,9,4,8,7,3,12,5,2,8,10,11), nrow = 3, ncol = 5, byrow = TRUE)
barplot(values, main = "total revenue", names.arg = months, xlab = "month", ylab = "revenue", col = colors)
legend("topleft", regions, cex = 1.3, fill = colors)
boxplot(BikeData$distance, data = BikeData, xlab = "distance", main = "Sales Data")
boxplot(x)
boxplot(values)
par(mfrow = c(3,2))
layout(matrix(c(1,2)), heights = c(2,1))
layout(1)
par(mfrow=c(1,1))
x = data.frame(foo = 1:4, bar = c(F, T, F, F))
x$foo[x$bar==F]
x = list(id = 1:4, bar = 0.6)
x
x = data.frame(foo = 1:4, bar = c(F, T, F, F))
x
x = list(id = 1:4, bar = 0.6)
x
x[1]
x <- matrix(1:6, 2, 3)
x[1, ]
x <- c("a", "b", "c", "c", "d", "a")
x[c(1, 3, 4)]
#Data consisting of two variables - bivariate data
#more than two variables - multivariate data
# most real time data is multivariate
# correlation coefficient - The statistical tool that measures the strength and direction of the linear relationship between two numerical variables
height = c(180,176,144,195,159,185,166,173,149,168)
weight = c(87,55,52,94,95,59,85,66,73,49)
plot(type = "p", height, weight)
plot(type = "line", height, weight)
plot(type = "l", height, weight)
plot(type = "d", height, weight)
plot(type = "p", height, weight)
plot(type = "dotted", height, weight)
plot(type = "p", height, weight)
plot(type = "p", weight, height)
plot(type = "p", height, weight)
cor(BikeData$distance,BikeData$time)
#Error in cor(BikeData$distane, BikeData$time) : 'x' must be numeric
cor(BikeData$distance,BikeData$time)
plot(BikeData$distance,BikeData$time)
cor(BikeData$distance,BikeData$speed)
library(corrplot)
corrplot(result,method="circle",type="upper")
plot(BikeData$distance,BikeData$speed,col="red")
which(BikeData$speed==max(BikeData))
which(BikeData$speed==max(BikeData$speed))
library(caret)
library(NeuralNetTools)
library(SDSFoundations)
linFit(menMile$Year, menMile$Record, 1)
WR=WorldRecords
menMile <- WR[WR$Event=='Mens Mile',]
womenMile <-WR[WR$Event=='Womens Mile',]
plot(menMile$Year, menMile$Record, main="Mens + Mile World Records", xlab="Year", ylab="World Record Distance (m)", pch=16)
plot(womenMile$Year, womenMile$Record, main="Womens + Mile World Records", xlab="Year", ylab="World Record Distance (m)", pch=16)
library(SDSFoundations)
linFit(menMile$Year, menMile$Record, 1)
linFit(womenMile$Year,womenMile$Record, 2)
#Mathematical modeling
# Mathematical modeling involves creating a set of mathematical equations that describes a situation, solving those equations, and using them to understand the real life problem
# Model can also be used to predict what a system will do for different values of the independent variable. Lastly, a model can be used to estimate quantities that are difficult to evaluate exactly
# The goal is not to produce an exact copy of the "real object" but rather to give a representation of some aspect of the real thing.
# Slope - the coefficient of x
# Rate of change - f(b) - f(a) / (b-a)
hotel = linear_tips
cor(hotel$meal_amt, hotel$tips)
linFit(sample$x, sample$y)
mu = 10000
xbar = 9900
sigma = 120
n = 30
alpha = 0.05
cv = qnorm(1-alpha) #qnorm gives x value
cv = -cv
cv
z = (xbar-mu)/(sigma/sqrt(n))
z
#compute p value
p = pnorm
library(BSDA)
x = rnorm(mean = 9900, sd = 110, n = 30)
#two tail test
mu = 15.4
xbar = 14.6
sigma = 2.5
n = 35
alpha = 0.05
sv = qnorm(1-alpha/2) #qnorm gives z value
cv = c(-cv, cv)
cv
z = (xbar-mu)/(sigma/sqrt(n))
z
#compute p value
p = 2-pnorm(z)
p
# F-distribution
#find the 95th percentile of the F distribution with (5,2) degrees of freedom.
cv = qf(.95, df1 = 5, df2 = 2)
pf(2.448, 3,14)
# F statistic for two population variances
# Taken values
alpha = 0.01
n1 = 6
n2 = 6
pop1.var = 5
pop2.var = 4.8
df1 = n1 - 1
df2 = n2 - 1
cv = qf(1-alpha, df1, df2)
cv
F = pop1.var/pop2.var
#anova in R - compare 3 or more pop.mean. Anova is analysis of variants
# primary principle of anova is it stacks according to factor variable
Group1 = c(2,3,7,2,6)
Group2 = c(10,8,7,5,10)
Group3 = c(10,13,14,13,15)
combined_groups = data.frame(cbind(Group1, Group2, Group3))
stacked_groups = stack(combined_groups)
stacked_groups
anova_results = aov(values~ind, data=stacked_groups)
summary(anova_results)
#Answer
#H0:mu>=10000 Ha:mu<10000 So, lower tail z test
mu=10000
xbar=9900
sigma=120
n=30
alpha=0.05
#finding the critical value
cv=qnorm(1-alpha) #qnorm gives z value
cv=-cv
cv
#finding the test statistic for z
z=(xbar-mu)/(sigma/sqrt(n))
z
#the result can be confirmed with p value or z value
#compute p value
p=pnorm(z)
p
